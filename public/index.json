[{"content":"Hunyuan3D-2.1加入了对PBR material的支持，以下是我在尝试该项目时遇到的问题和解决方法的总结。\nTroubleshooting:\nImportError: libSM.so.6: cannot open shared object file: No such file or directory Ubuntu系统上的解决方案：\nsudo apt update sudo apt install libsm6 libxrender1 libxext6 Other install packages\npip install sentencepiece # download the hy3dgen for txt2img from Hunyuan3D-2 分享一下改进后的img-to-3D demo.py\nimport sys sys.path.insert(0, \u0026#39;./hy3dshape\u0026#39;) sys.path.insert(0, \u0026#39;./hy3dpaint\u0026#39;) from PIL import Image from hy3dshape.rembg import BackgroundRemover from hy3dshape.pipelines import Hunyuan3DDiTFlowMatchingPipeline import os from textureGenPipeline import Hunyuan3DPaintPipeline, Hunyuan3DPaintConfig try: from torchvision_fix import apply_fix apply_fix() except ImportError: print(\u0026#34;Warning: torchvision_fix module not found, proceeding without compatibility fix\u0026#34;) except Exception as e: print(f\u0026#34;Warning: Failed to apply torchvision fix: {e}\u0026#34;) # shape model_path = \u0026#39;tencent/Hunyuan3D-2.1\u0026#39; pipeline_shapegen = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(model_path) image_path = \u0026#39;assets/example_images/mmexportde235211f304fd83ec9d60e38c9f6f0b_1747975667632.png\u0026#39; filename = os.path.basename(image_path).split(\u0026#39;.\u0026#39;)[0] image = Image.open(image_path).convert(\u0026#34;RGBA\u0026#34;) if image.mode == \u0026#39;RGB\u0026#39;: rembg = BackgroundRemover() image = rembg(image) save_folder = os.path.join(\u0026#39;output\u0026#39;, filename) os.makedirs(save_folder, exist_ok=True) mesh = pipeline_shapegen(image=image)[0] mesh.export(os.path.join(output_folder, filename + \u0026#39;.glb\u0026#39;)) # paint max_num_view = 6 # can be 6 to 9 resolution = 512 # can be 768 or 512 conf = Hunyuan3DPaintConfig(max_num_view, resolution) conf.realesrgan_ckpt_path = \u0026#34;hy3dpaint/ckpt/RealESRGAN_x4plus.pth\u0026#34; conf.multiview_cfg_path = \u0026#34;hy3dpaint/cfgs/hunyuan-paint-pbr.yaml\u0026#34; conf.custom_pipeline = \u0026#34;hy3dpaint/hunyuanpaintpbr\u0026#34; paint_pipeline = Hunyuan3DPaintPipeline(conf) output_mesh_path = filename + \u0026#39;_textured.glb\u0026#39; output_mesh_path = paint_pipeline( mesh_path = os.path.join(output_folder, filename + \u0026#39;.glb\u0026#39;), image_path = image_path, output_mesh_path = os.path.join(output_folder, output_mesh_path) ) 以及txt-to-3D_demo.py\nimport sys sys.path.insert(0, \u0026#39;./hy3dshape\u0026#39;) sys.path.insert(0, \u0026#39;./hy3dpaint\u0026#39;) from PIL import Image from hy3dshape.rembg import BackgroundRemover from hy3dshape.pipelines import Hunyuan3DDiTFlowMatchingPipeline import os import time import torch from hy3dshape.utils import logger from hy3dpaint.convert_utils import create_glb_with_pbr_materials from gradio_app import export_mesh, randomize_seed_fn, quick_convert_with_obj2gltf from hy3dgen.text2image import HunyuanDiTPipeline from textureGenPipeline import Hunyuan3DPaintPipeline, Hunyuan3DPaintConfig from hy3dshape.pipelines import export_to_trimesh from hy3dshape import FaceReducer, FloaterRemover, DegenerateFaceRemover, MeshSimplifier, \\ Hunyuan3DDiTFlowMatchingPipeline try: from torchvision_fix import apply_fix apply_fix() except ImportError: print(\u0026#34;Warning: torchvision_fix module not found, proceeding without compatibility fix\u0026#34;) except Exception as e: print(f\u0026#34;Warning: Failed to apply torchvision fix: {e}\u0026#34;) def _gen_shape( caption=None, image=None, mv_image_front=None, mv_image_back=None, mv_image_left=None, mv_image_right=None, steps=50, guidance_scale=7.5, seed=1234, octree_resolution=256, check_box_rembg=False, num_chunks=200000, randomize_seed: bool = False, ): # if not MV_MODE and image is None and caption is None: # raise gr.Error(\u0026#34;Please provide either a caption or an image.\u0026#34;) # if MV_MODE: # if mv_image_front is None and mv_image_back is None \\ # and mv_image_left is None and mv_image_right is None: # raise gr.Error(\u0026#34;Please provide at least one view image.\u0026#34;) # image = {} # if mv_image_front: # image[\u0026#39;front\u0026#39;] = mv_image_front # if mv_image_back: # image[\u0026#39;back\u0026#39;] = mv_image_back # if mv_image_left: # image[\u0026#39;left\u0026#39;] = mv_image_left # if mv_image_right: # image[\u0026#39;right\u0026#39;] = mv_image_right seed = int(randomize_seed_fn(seed, randomize_seed)) octree_resolution = int(octree_resolution) if caption: print(\u0026#39;prompt is\u0026#39;, caption) # save_folder = gen_save_folder() # stats = { # \u0026#39;model\u0026#39;: { # \u0026#39;shapegen\u0026#39;: f\u0026#39;{args.model_path}/{args.subfolder}\u0026#39;, # \u0026#39;texgen\u0026#39;: f\u0026#39;{args.texgen_model_path}\u0026#39;, # }, # \u0026#39;params\u0026#39;: { # \u0026#39;caption\u0026#39;: caption, # \u0026#39;steps\u0026#39;: steps, # \u0026#39;guidance_scale\u0026#39;: guidance_scale, # \u0026#39;seed\u0026#39;: seed, # \u0026#39;octree_resolution\u0026#39;: octree_resolution, # \u0026#39;check_box_rembg\u0026#39;: check_box_rembg, # \u0026#39;num_chunks\u0026#39;: num_chunks, # } # } time_meta = {} if image is None: start_time = time.time() try: t2i_worker = HunyuanDiTPipeline(\u0026#39;Tencent-Hunyuan/HunyuanDiT-v1.1-Diffusers-Distilled\u0026#39;) image = t2i_worker(caption) except Exception as e: raise Exception(f\u0026#34;Text to 3D is disable. \\ Please enable it by `python gradio_app.py --enable_t23d`.\u0026#34;) time_meta[\u0026#39;text2image\u0026#39;] = time.time() - start_time # remove disk io to make responding faster, uncomment at your will. # image.save(os.path.join(save_folder, \u0026#39;input.png\u0026#39;)) rmbg_worker = BackgroundRemover() if MV_MODE: start_time = time.time() for k, v in image.items(): if check_box_rembg or v.mode == \u0026#34;RGB\u0026#34;: img = rmbg_worker(v.convert(\u0026#39;RGB\u0026#39;)) image[k] = img time_meta[\u0026#39;remove background\u0026#39;] = time.time() - start_time else: if check_box_rembg or image.mode == \u0026#34;RGB\u0026#34;: start_time = time.time() image = rmbg_worker(image.convert(\u0026#39;RGB\u0026#39;)) time_meta[\u0026#39;remove background\u0026#39;] = time.time() - start_time # remove disk io to make responding faster, uncomment at your will. # image.save(os.path.join(save_folder, \u0026#39;rembg.png\u0026#39;)) # image to white model start_time = time.time() generator = torch.Generator() generator = generator.manual_seed(int(seed)) i23d_worker = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained( args.model_path, subfolder=args.subfolder, use_safetensors=False, device=args.device, ) outputs = i23d_worker( image=image, num_inference_steps=steps, guidance_scale=guidance_scale, generator=generator, octree_resolution=octree_resolution, num_chunks=num_chunks, output_type=\u0026#39;mesh\u0026#39; ) time_meta[\u0026#39;shape generation\u0026#39;] = time.time() - start_time logger.info(\u0026#34;---Shape generation takes %s seconds ---\u0026#34; % (time.time() - start_time)) tmp_start = time.time() mesh = export_to_trimesh(outputs)[0] time_meta[\u0026#39;export to trimesh\u0026#39;] = time.time() - tmp_start # stats[\u0026#39;number_of_faces\u0026#39;] = mesh.faces.shape[0] # stats[\u0026#39;number_of_vertices\u0026#39;] = mesh.vertices.shape[0] # stats[\u0026#39;time\u0026#39;] = time_meta main_image = image if not MV_MODE else image[\u0026#39;front\u0026#39;] return mesh, main_image, seed def generation_all( caption=None, image=None, mv_image_front=None, mv_image_back=None, mv_image_left=None, mv_image_right=None, steps=50, guidance_scale=7.5, seed=1234, octree_resolution=256, check_box_rembg=False, num_chunks=200000, randomize_seed: bool = False, ): start_time_0 = time.time() mesh, image, seed = _gen_shape( caption, image, mv_image_front=mv_image_front, mv_image_back=mv_image_back, mv_image_left=mv_image_left, mv_image_right=mv_image_right, steps=steps, guidance_scale=guidance_scale, seed=seed, octree_resolution=octree_resolution, check_box_rembg=check_box_rembg, num_chunks=num_chunks, randomize_seed=randomize_seed, ) save_folder = os.path.join(\u0026#39;output\u0026#39;, \u0026#39;_\u0026#39;.join(caption.split())) os.makedirs(save_folder, exist_ok=True) path = export_mesh(mesh, save_folder, textured=False) print(path) print(\u0026#39;=\u0026#39;*40) # tmp_time = time.time() # mesh = floater_remove_worker(mesh) # mesh = degenerate_face_remove_worker(mesh) # logger.info(\u0026#34;---Postprocessing takes %s seconds ---\u0026#34; % (time.time() - tmp_time)) # stats[\u0026#39;time\u0026#39;][\u0026#39;postprocessing\u0026#39;] = time.time() - tmp_time tmp_time = time.time() face_reduce_worker = FaceReducer() mesh = face_reduce_worker(mesh) # path = export_mesh(mesh, save_folder, textured=False, type=\u0026#39;glb\u0026#39;) path = export_mesh(mesh, save_folder, textured=False, type=\u0026#39;obj\u0026#39;) # 这样操作也会 core dump logger.info(\u0026#34;---Face Reduction takes %s seconds ---\u0026#34; % (time.time() - tmp_time)) # stats[\u0026#39;time\u0026#39;][\u0026#39;face reduction\u0026#39;] = time.time() - tmp_time tmp_time = time.time() text_path = os.path.join(save_folder, f\u0026#39;textured_mesh.obj\u0026#39;) conf = Hunyuan3DPaintConfig(max_num_view=8, resolution=768) conf.realesrgan_ckpt_path = \u0026#34;hy3dpaint/ckpt/RealESRGAN_x4plus.pth\u0026#34; conf.multiview_cfg_path = \u0026#34;hy3dpaint/cfgs/hunyuan-paint-pbr.yaml\u0026#34; conf.custom_pipeline = \u0026#34;hy3dpaint/hunyuanpaintpbr\u0026#34; tex_pipeline = Hunyuan3DPaintPipeline(conf) path_textured = tex_pipeline(mesh_path=path, image_path=image, output_mesh_path=text_path, save_glb=False) logger.info(\u0026#34;---Texture Generation takes %s seconds ---\u0026#34; % (time.time() - tmp_time)) # stats[\u0026#39;time\u0026#39;][\u0026#39;texture generation\u0026#39;] = time.time() - tmp_time tmp_time = time.time() # Convert textured OBJ to GLB using obj2gltf with PBR support glb_path_textured = os.path.join(save_folder, \u0026#39;textured_mesh.glb\u0026#39;) conversion_success = quick_convert_with_obj2gltf(path_textured, glb_path_textured) logger.info(\u0026#34;---Convert textured OBJ to GLB takes %s seconds ---\u0026#34; % (time.time() - tmp_time)) # stats[\u0026#39;time\u0026#39;][\u0026#39;convert textured OBJ to GLB\u0026#39;] = time.time() - tmp_time # stats[\u0026#39;time\u0026#39;][\u0026#39;total\u0026#39;] = time.time() - start_time_0 # model_viewer_html_textured = build_model_viewer_html(save_folder, # height=HTML_HEIGHT, # width=HTML_WIDTH, textured=True) if args.low_vram_mode: torch.cuda.empty_cache() # return ( # gr.update(value=path), # gr.update(value=glb_path_textured), # model_viewer_html_textured, # stats, # seed, # ) if __name__==\u0026#34;__main__\u0026#34;: import argparse parser = argparse.ArgumentParser() parser.add_argument(\u0026#34;--model_path\u0026#34;, type=str, default=\u0026#39;tencent/Hunyuan3D-2.1\u0026#39;) parser.add_argument(\u0026#34;--subfolder\u0026#34;, type=str, default=\u0026#39;hunyuan3d-dit-v2-1\u0026#39;) parser.add_argument(\u0026#34;--texgen_model_path\u0026#34;, type=str, default=\u0026#39;tencent/Hunyuan3D-2.1\u0026#39;) parser.add_argument(\u0026#39;--caption\u0026#39;, type=str, default=\u0026#34;a lovely rabbit eating carrots\u0026#34;) parser.add_argument(\u0026#39;--device\u0026#39;, type=str, default=\u0026#39;cuda\u0026#39;) parser.add_argument(\u0026#39;--low_vram_mode\u0026#39;, action=\u0026#39;store_true\u0026#39;) args = parser.parse_args() caption = args.caption MV_MODE = False generation_all(caption=caption) ","permalink":"http://localhost:1313/posts/hunyuan3d-2.1-pitfall/hunyuan3d-2.1-pitfall/","summary":"\u003cp\u003eHunyuan3D-2.1加入了对PBR material的支持，以下是我在尝试该项目时遇到的问题和解决方法的总结。\u003c/p\u003e\n\u003cp\u003eTroubleshooting:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eImportError: libSM.so.6: cannot open shared object file: No such file or directory\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eUbuntu系统上的解决方案：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo apt update\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esudo apt install libsm6 libxrender1 libxext6\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eOther install packages\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epip install sentencepiece\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# download the hy3dgen for txt2img from Hunyuan3D-2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e分享一下改进后的img-to-3D demo.py\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e sys\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esys\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einsert(\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;./hy3dshape\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esys\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003einsert(\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;./hy3dpaint\u0026#39;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e PIL \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e Image\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e hy3dshape.rembg \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e BackgroundRemover\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e hy3dshape.pipelines \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e Hunyuan3DDiTFlowMatchingPipeline\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e os\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e textureGenPipeline \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e Hunyuan3DPaintPipeline, Hunyuan3DPaintConfig\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e torchvision_fix \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e apply_fix\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    apply_fix()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eImportError\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Warning: torchvision_fix module not found, proceeding without compatibility fix\u0026#34;\u003c/span\u003e)                                      \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eException\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eas\u003c/span\u003e e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    print(\u003cspan style=\"color:#e6db74\"\u003ef\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Warning: Failed to apply torchvision fix: \u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e{\u003c/span\u003ee\u003cspan style=\"color:#e6db74\"\u003e}\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# shape\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emodel_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;tencent/Hunyuan3D-2.1\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epipeline_shapegen \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Hunyuan3DDiTFlowMatchingPipeline\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efrom_pretrained(model_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eimage_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;assets/example_images/mmexportde235211f304fd83ec9d60e38c9f6f0b_1747975667632.png\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003efilename \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ebasename(image_path)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003esplit(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;.\u0026#39;\u003c/span\u003e)[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eimage \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Image\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eopen(image_path)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003econvert(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;RGBA\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e image\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emode \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;RGB\u0026#39;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    rembg \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e BackgroundRemover()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e rembg(image)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003esave_folder \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(\u003cspan style=\"color:#e6db74\"\u003e\u0026#39;output\u0026#39;\u003c/span\u003e, filename)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eos\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emakedirs(save_folder, exist_ok\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#66d9ef\"\u003eTrue\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emesh \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pipeline_shapegen(image\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eimage)[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emesh\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eexport(os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(output_folder, filename \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;.glb\u0026#39;\u003c/span\u003e))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# paint\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003emax_num_view \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e6\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e# can be 6 to 9\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eresolution \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e512\u003c/span\u003e  \u003cspan style=\"color:#75715e\"\u003e# can be 768 or 512\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econf \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Hunyuan3DPaintConfig(max_num_view, resolution)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003erealesrgan_ckpt_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;hy3dpaint/ckpt/RealESRGAN_x4plus.pth\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003emultiview_cfg_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;hy3dpaint/cfgs/hunyuan-paint-pbr.yaml\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econf\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ecustom_pipeline \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;hy3dpaint/hunyuanpaintpbr\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epaint_pipeline \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e Hunyuan3DPaintPipeline(conf)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eoutput_mesh_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e filename \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;_textured.glb\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eoutput_mesh_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e paint_pipeline(\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    mesh_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(output_folder, filename \u003cspan style=\"color:#f92672\"\u003e+\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;.glb\u0026#39;\u003c/span\u003e), \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    image_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e image_path,\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    output_mesh_path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e os\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003epath\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin(output_folder, output_mesh_path)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e以及txt-to-3D_demo.py\u003c/p\u003e","title":"Hunyuan3D-2.1 Pitfall"},{"content":"Git 创建仓库并同步到远程仓库 初始化 git init 添加仓库 git remote add origin git@github.com:username/xxx.git git remote remove origin git remote set-url \u0026lt;REMOTE-NAME\u0026gt; \u0026lt;NEW-URL\u0026gt; git remote rename \u0026lt;old-name\u0026gt; \u0026lt;new-name\u0026gt; 查看远程 git remote -v / git remote remove origin 创建新分支 git branch 查看本地分支 git branch -a 查看远程、本地所有分支 git branch -m new_branch_name 创建空分支 git checkout --orphan new_branch_name git reset \u0026amp; git clean -fdx git commit --allow-empty -m \u0026#34;Initial commit\u0026#34; 提交仓库 git status git add . git commit -m \u0026#39;commit_message\u0026#39; git push/pull origin local_branch:remote_branch 分支操作 git push -u origin \u0026lt;remote_branch_name\u0026gt; git push --set-upstream origin \u0026lt;remote_branch_name\u0026gt; # 设置本地分支关联的远程分支 git checkout \u0026lt;branch_name\u0026gt; # 切换本地分支 git checkout -b \u0026lt;branch_name\u0026gt; # 创建一个本地远程分支 git branch -v # 查看本地分支信息 git branch -r # 查看远程分支 git branch -a # 查看全部分支 git branch -vv # 查看关联分支信息 远程仓库多分支条件下，git clone只会克隆主分支。如果想要克隆其他分支：\ngit clone \u0026lt;仓库URL\u0026gt; –branch \u0026lt;分支名\u0026gt; –single-branch 本地仓库未跟踪远程分支，可以使用以下命令手动关联分支：\ngit branch -r git checkout -b \u0026lt;本地分支名\u0026gt; origin/\u0026lt;远程分支名\u0026gt; ","permalink":"http://localhost:1313/posts/git-command-summarization/git-command-summarization/","summary":"\u003ch1 id=\"git-创建仓库并同步到远程仓库\"\u003eGit 创建仓库并同步到远程仓库\u003c/h1\u003e\n\u003ch3 id=\"初始化\"\u003e初始化\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit init\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"添加仓库\"\u003e添加仓库\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit remote add origin git@github.com:username/xxx.git\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit remote remove origin\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit remote set-url \u0026lt;REMOTE-NAME\u0026gt; \u0026lt;NEW-URL\u0026gt;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit remote rename \u0026lt;old-name\u0026gt; \u0026lt;new-name\u0026gt;\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"查看远程\"\u003e查看远程\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit remote -v / git remote remove origin\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"创建新分支\"\u003e创建新分支\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit branch 查看本地分支\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit branch -a 查看远程、本地所有分支\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit branch -m new_branch_name\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"创建空分支\"\u003e创建空分支\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit checkout --orphan new_branch_name\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit reset \u0026amp; git clean -fdx\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit commit --allow-empty -m \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Initial commit\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"提交仓库\"\u003e提交仓库\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit status\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit add .\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit commit -m \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;commit_message\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit push/pull origin local_branch:remote_branch\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch1 id=\"分支操作\"\u003e分支操作\u003c/h1\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit push -u origin \u0026lt;remote_branch_name\u0026gt;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit push --set-upstream origin \u0026lt;remote_branch_name\u0026gt; \u003cspan style=\"color:#75715e\"\u003e# 设置本地分支关联的远程分支\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit checkout \u0026lt;branch_name\u0026gt; \u003cspan style=\"color:#75715e\"\u003e# 切换本地分支\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit checkout -b \u0026lt;branch_name\u0026gt; \u003cspan style=\"color:#75715e\"\u003e# 创建一个本地远程分支\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit branch -v \u003cspan style=\"color:#75715e\"\u003e# 查看本地分支信息\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit branch -r \u003cspan style=\"color:#75715e\"\u003e# 查看远程分支\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit branch -a \u003cspan style=\"color:#75715e\"\u003e# 查看全部分支\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit branch -vv \u003cspan style=\"color:#75715e\"\u003e# 查看关联分支信息\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e远程仓库多分支条件下，git clone只会克隆主分支。如果想要克隆其他分支：\u003c/p\u003e","title":"Git Command Summarization"},{"content":"在 Blender 中给摄像机添加环绕物体一周的动作，常用方法是： ✅ 方法一：使用「空物体」控制摄像机环绕运动（推荐） 添加空物体 Empty：\n在 3D 视图中按 Shift + A → 空物体（Empty） → Plain Axes。\n把它放在你想环绕的物体中心（或目标）上。\n设置摄像机的父对象：\n选中摄像机，然后 Shift 选中空物体。\n按 Ctrl + P → 选择 Object (对象) 进行父子关系绑定。\n现在移动或旋转空物体，摄像机会跟着动。\n让空物体旋转：\n选中空物体。\n在时间轴开始帧设置初始旋转（如 Z 轴为 0°），按 I → Rotation 插入关键帧。\n移动到结束帧（如帧 120），将空物体 Z 轴旋转设为 360°，再按 I → Rotation。\n播放时，摄像机会随空物体环绕目标旋转一圈。\n（可选）设置摄像机总是朝向目标：\n选中摄像机，在「约束（Constraints）」面板中添加 Track To 约束。\n设置目标为你想要围绕的对象（或同一个 Empty）。\n设置 Track Axis 为 -Z，Up Axis 为 Y。\n✅ 方法二：直接使用路径 Path 控制 添加曲线路径：\nShift + A → 曲线（Curve） → Circle 或自定义路径。\n将路径环绕物体放置。\n让摄像机沿路径运动：\n选中摄像机 → 添加约束（Constraints）→ Follow Path。\n目标设置为刚添加的路径。\n勾选 Follow Curve 或 Follow Rotation。\n动画控制：\n在约束面板点击 Animate Path 或在 Path 属性中设置 Evaluation Time 动画关键帧。 让摄像机朝向物体：\n同样使用 Track To 约束或 Damped Track 约束，让摄像机始终面向目标。 哪个方法更好？ 环绕一圈：空物体方式更直观且控制自由。\n沿复杂轨迹飞行：路径方式更适合。\n备注： E快捷键挤出，Ctrl + B 倒角边 注意cycles渲染的时候，如果速度慢，查看偏好设置→系统中的cycles渲染引擎是否选中CUDA。 勾选动态采样，减少最大采样数，设置最小采样数（32~64），勾选降噪下的使用GPU，加快渲染速度。\n","permalink":"http://localhost:1313/posts/blender-camera-animation/","summary":"\u003ch3 id=\"在-blender-中给摄像机添加环绕物体一周的动作常用方法是\"\u003e在 Blender 中给摄像机添加环绕物体一周的动作，常用方法是：\u003c/h3\u003e\n\u003ch2 id=\"-方法一使用空物体控制摄像机环绕运动推荐\"\u003e✅ 方法一：使用「空物体」控制摄像机环绕运动（推荐）\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e添加空物体 Empty：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e在 3D 视图中按 Shift + A → 空物体（Empty） → Plain Axes。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e把它放在你想环绕的物体中心（或目标）上。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e设置摄像机的父对象：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e选中摄像机，然后 Shift 选中空物体。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e按 \u003ccode\u003eCtrl + P\u003c/code\u003e → 选择 \u003ccode\u003eObject (对象)\u003c/code\u003e 进行父子关系绑定。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e现在移动或旋转空物体，摄像机会跟着动。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e让空物体旋转：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e选中空物体。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e在时间轴开始帧设置初始旋转（如 Z 轴为 0°），按 \u003ccode\u003eI → Rotation\u003c/code\u003e 插入关键帧。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e移动到结束帧（如帧 120），将空物体 Z 轴旋转设为 360°，再按 \u003ccode\u003eI → Rotation\u003c/code\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e播放时，摄像机会随空物体环绕目标旋转一圈。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e（可选）设置摄像机总是朝向目标：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e选中摄像机，在「约束（Constraints）」面板中添加 Track To 约束。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e设置目标为你想要围绕的对象（或同一个 Empty）。\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e设置 \u003ccode\u003eTrack Axis\u003c/code\u003e 为 \u003ccode\u003e-Z\u003c/code\u003e，\u003ccode\u003eUp Axis\u003c/code\u003e 为 \u003ccode\u003eY\u003c/code\u003e。\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"-方法二直接使用路径-path-控制\"\u003e✅ 方法二：直接使用路径 Path 控制\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e添加曲线路径：\u003c/p\u003e","title":"Blender Camera Animation"},{"content":"Bash prompt for training a ControlNet on Stable Diffusion v3.5\nexport MODEL_DIR=\u0026#34;stabilityai/stable-diffusion-3.5-medium\u0026#34; export OUTPUT_DIR=\u0026#34;sd3-controlnet-out\u0026#34; accelerate launch train_controlnet_sd3.py \\ --pretrained_model_name_or_path=$MODEL_DIR \\ --output_dir=$OUTPUT_DIR \\ --dataset_name=\u0026#34;\u0026#34;fusing/fill50k\u0026#34; \\ --resolution=1024 \\ --learning_rate=1e-5 \\ --max_train_steps=15000 \\ --validation_image \u0026#34;./conditioning_image_1.png\u0026#34; \u0026#34;./conditioning_image_2.png\u0026#34; \\ --validation_prompt \u0026#34;red circle with blue background\u0026#34; \u0026#34;cyan circle with brown floral background\u0026#34; \\ --validation_steps=100 \\ --train_batch_size=1 \\ --gradient_accumulation_steps=4 Full tutorials should be referred in the \u0026ldquo;diffusers\u0026rdquo; github page: https://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sd3.md\n","permalink":"http://localhost:1313/posts/sd3.5-controlnet-pitfall/","summary":"\u003cp\u003eBash prompt for training a ControlNet on Stable Diffusion v3.5\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexport MODEL_DIR\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;stabilityai/stable-diffusion-3.5-medium\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eexport OUTPUT_DIR\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;sd3-controlnet-out\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eaccelerate launch train_controlnet_sd3.py \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    --pretrained_model_name_or_path\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e$MODEL_DIR \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    --output_dir\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e$OUTPUT_DIR \u003cspan style=\"color:#ae81ff\"\u003e\\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#ae81ff\"\u003e\u003c/span\u003e    --dataset_name\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;\u0026#34;\u003c/span\u003efusing/fill50k\u003cspan style=\"color:#e6db74\"\u003e\u0026#34; \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --resolution=1024 \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --learning_rate=1e-5 \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --max_train_steps=15000 \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --validation_image \u0026#34;\u003c/span\u003e./conditioning_image_1.png\u003cspan style=\"color:#e6db74\"\u003e\u0026#34; \u0026#34;\u003c/span\u003e./conditioning_image_2.png\u003cspan style=\"color:#e6db74\"\u003e\u0026#34; \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --validation_prompt \u0026#34;\u003c/span\u003ered circle with blue background\u003cspan style=\"color:#e6db74\"\u003e\u0026#34; \u0026#34;\u003c/span\u003ecyan circle with brown floral background\u003cspan style=\"color:#e6db74\"\u003e\u0026#34; \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --validation_steps=100 \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --train_batch_size=1 \\\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#e6db74\"\u003e    --gradient_accumulation_steps=4\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eFull tutorials should be referred in the \u0026ldquo;diffusers\u0026rdquo; github page:\n\u003ca href=\"https://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sd3.md\"\u003ehttps://github.com/huggingface/diffusers/blob/main/examples/controlnet/README_sd3.md\u003c/a\u003e\u003c/p\u003e","title":"SD3.5 ControlNet Pitfall"},{"content":"LoRAs also need to be used with another model:\nfrom diffusers import AutoPipelineForText2Image import torch pipeline = AutoPipelineForText2Image.from_pretrained(\u0026#34;stabilityai/stable-diffusion-xl-base-1.0\u0026#34;, torch_dtype=torch.float16).to(\u0026#34;cuda\u0026#34;) Then use the load_lora_weights() method to load the ostris/super-cereal-sdxl-lora weights and specify the weights filename from the repository:\npipeline.load_lora_weights(\u0026#34;ostris/super-cereal-sdxl-lora\u0026#34;, weight_name=\u0026#34;cereal_box_sdxl_v1.safetensors\u0026#34;) prompt = \u0026#34;bears, pizza bites\u0026#34; image = pipeline(prompt).images[0] image Replace the Model and the Lora weights file and folder in the code.\n","permalink":"http://localhost:1313/posts/loading-lora-weights-in-stable-diffusion-model/","summary":"\u003cp\u003eLoRAs also need to be used with another model:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e diffusers \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e AutoPipelineForText2Image\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e torch\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epipeline \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e AutoPipelineForText2Image\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efrom_pretrained(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;stabilityai/stable-diffusion-xl-base-1.0\u0026#34;\u003c/span\u003e, torch_dtype\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etorch\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003efloat16)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eto(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;cuda\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThen use the load_lora_weights() method to load the ostris/super-cereal-sdxl-lora weights and specify the weights filename from the repository:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epipeline\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eload_lora_weights(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;ostris/super-cereal-sdxl-lora\u0026#34;\u003c/span\u003e, weight_name\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;cereal_box_sdxl_v1.safetensors\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eprompt \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;bears, pizza bites\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eimage \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e pipeline(prompt)\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eimages[\u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e]\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eimage\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eReplace the \u003c!-- raw HTML omitted --\u003eModel\u003c!-- raw HTML omitted --\u003e and the \u003c!-- raw HTML omitted --\u003eLora weights file and folder \u003c!-- raw HTML omitted --\u003ein the code.\u003c/p\u003e","title":"Loading Lora Weights in Stable Diffusion Model"},{"content":"云平台：AutoDL 模型加载工具：Ollama 参考：https://github.com/ollama/ollama/blob/main/docs/linux.md\n下载Ollama 服务器上下载ollama比较慢，因此我使用浏览器先下载到本地电脑上。\nhttps://ollama.com/download/ollama-linux-amd64.tgz复制到浏览器进行下载 下载好以后，使用FileZilla等工具上传到云服务器上，这里我上传到autodl-tmp文件夹下。 打开一个terminal，解压下载的文件包：\ntar -C /usr -xzf ollama-linux-amd64.tgz 启用ollama ollama serve 再打开一个terminal，检查一下ollama是否启用 ollama -v 这里可以看到ollama版本，说明启用成功。 拉取模型 这里以deepseek-r1:32b为例进行拉取\nollama pull deepseek-r1:32b 下载过程中可能有掉速，Ctrl+C掉以后再重新ollama pull可以继续下载。 下载完成以后可以查看一下模型列表：\nollama list 运行模型：\nollama run deepseek-r1:32b 测试了一个很常见的，却有许多模型答错的问题：9.11和9.9比大小 这个模型的链式推理很有人味儿，很有吸引力，这可能就是这个模型受很多人关注和称赞的原因吧\n","permalink":"http://localhost:1313/posts/full-process-of-deploying-deepseek-on-remote-server/","summary":"\u003cp\u003e云平台：AutoDL\n模型加载工具：Ollama\n参考：https://github.com/ollama/ollama/blob/main/docs/linux.md\u003c/p\u003e\n\u003ch2 id=\"下载ollama\"\u003e下载Ollama\u003c/h2\u003e\n\u003cp\u003e服务器上下载ollama比较慢，因此我使用浏览器先下载到本地电脑上。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://ollama.com/download/ollama-linux-amd64.tgz\"\u003ehttps://ollama.com/download/ollama-linux-amd64.tgz\u003c/a\u003e复制到浏览器进行下载\n下载好以后，使用FileZilla等工具上传到云服务器上，这里我上传到autodl-tmp文件夹下。\n打开一个terminal，解压下载的文件包：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003etar -C /usr -xzf ollama-linux-amd64.tgz\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"启用ollama\"\u003e启用ollama\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eollama serve\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"再打开一个terminal检查一下ollama是否启用\"\u003e再打开一个terminal，检查一下ollama是否启用\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eollama -v\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e这里可以看到ollama版本，说明启用成功。\n\u003cimg alt=\"版本查看\" loading=\"lazy\" src=\"/posts/full-process-of-deploying-deepseek-on-remote-server/image.png\"\u003e\u003c/p\u003e\n\u003ch2 id=\"拉取模型\"\u003e拉取模型\u003c/h2\u003e\n\u003cp\u003e这里以deepseek-r1:32b为例进行拉取\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eollama pull deepseek-r1:32b\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"拉取模型\" loading=\"lazy\" src=\"/posts/full-process-of-deploying-deepseek-on-remote-server/image-1.png\"\u003e\n\u003c!-- raw HTML omitted --\u003e下载过程中可能有掉速，Ctrl+C掉以后再重新ollama pull可以继续下载。\u003c!-- raw HTML omitted --\u003e\n下载完成以后可以查看一下模型列表：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eollama list\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003cimg alt=\"模型列表\" loading=\"lazy\" src=\"/posts/full-process-of-deploying-deepseek-on-remote-server/image-3.png\"\u003e\u003c/p\u003e\n\u003cp\u003e运行模型：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eollama run deepseek-r1:32b\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e测试了一个很常见的，却有许多模型答错的问题：9.11和9.9比大小\n\u003cimg alt=\"问题测试\" loading=\"lazy\" src=\"/posts/full-process-of-deploying-deepseek-on-remote-server/image-4.png\"\u003e\n这个模型的链式推理很有人味儿，很有吸引力，这可能就是这个模型受很多人关注和称赞的原因吧\u003c/p\u003e","title":"Full process of deploying deepseek on remote server"}]